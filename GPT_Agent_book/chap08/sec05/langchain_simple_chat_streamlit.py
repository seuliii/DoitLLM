import streamlit as st

from langchain_openai import ChatOpenAI #ì˜¤í”ˆAI ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ëž­ì²´ì¸ ì±—ë´‡
from langchain_core.chat_history import InMemoryChatMessageHistory,BaseChatMessageHistory  #ë©”ëª¨ë¦¬ì— ëŒ€í™” ê¸°ë¡ì„ ì €ìž¥
from langchain_core.runnables.history import RunnableWithMessageHistory #ë©”ì‹œì§€ ê¸°ë¡ì„ í™œìš©í•´ ì‹¤í–‰í•  ìˆ˜ ìžˆëŠ” WRAPPER í´ëž˜ìŠ¤
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage

from dotenv import load_dotenv

load_dotenv()
st.title("ðŸ’­ Chatbot")

#message : ì „ì²´ ë©”ì‹œì§€ ëª©ë¡
if "messages" not in st.session_state:
    st.session_state["messages"] = [
        SystemMessage("ë„ˆëŠ” ì‚¬ìš©ìžì˜ ì§ˆë¬¸ì— ì¹œì ˆí•˜ê²Œ ë‹µí•˜ëŠ” AI ì±—ë´‡ì´ì•¼")
    ]

#store : ì„¸ì…˜IDë³„ ë‚˜ë‰˜ëŠ” ëŒ€í™” ì´ë ¥ ê°ì²´ë¥¼ ë³´ê´€í•˜ëŠ” ì €ìž¥ì†Œ
if "store" not in st.session_state:
    st.session_state["store"] = {}

def get_session_history(session_id : str) -> BaseChatMessageHistory:
    if session_id not in st.session_state["store"]:
        st.session_state["store"][session_id] = InMemoryChatMessageHistory()
    return st.session_state["store"][session_id]

llm = ChatOpenAI(model="gpt-4o-mini")
with_message_history = RunnableWithMessageHistory(llm,get_session_history)

config= {"configurable" : {"session_id" : "abc2"}}

for msg in st.session_state.messages:
    if msg:
        if isinstance(msg,SystemMessage):
            st.chat_message("system").write(msg.content)
        elif isinstance(msg,AIMessage):
            st.chat_message("assistant").write(msg.content)
        elif isinstance(msg,HumanMessage):
            st.chat_message("user").write(msg.content)

if prompt := st.chat_input():
    print("user: " , prompt)
    st.session_state.messages.append(HumanMessage(prompt))
    st.chat_message("user").write(prompt)

    response = with_message_history.stream([HumanMessage(prompt)], config = config)

    ai_response_bucket = None
    with st.chat_message("assistant").empty():
        for r in response:
            if ai_response_bucket is None:
                ai_response_bucket = r
            else:
                ai_response_bucket += r
            print(r.content, end = '')
            st.markdown(ai_response_bucket.content)

    msg = ai_response_bucket.content
    st.session_state.messages.append(ai_response_bucket)
    #st.chat_message("assistant").write(msg)
    print('assistant: ', msg )
